{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AlphaVantage as av\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example we'll fetch the daily price history for Google stock.\n",
    "This returns a python dictionary that we need to split up into the desired fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = av.apicall(function='TIME_SERIES_DAILY', symbol='GOOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the keys are YYYY/MM/DD strings in a dict, so we need to sort to put them in chronological order\n",
    "dat_ord = sorted(dat['Time Series (Daily)'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_open = np.array([float(x[1]['1. open']) for x in dat_ord])\n",
    "dat_high = np.array([float(x[1]['2. high']) for x in dat_ord])\n",
    "dat_low = np.array([float(x[1]['3. low']) for x in dat_ord])\n",
    "dat_close = np.array([float(x[1]['4. close']) for x in dat_ord])\n",
    "dat_volume = np.array([float(x[1]['5. volume']) for x in dat_ord])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Data for ANN Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prices of different stocks will obviously have completely different prices.\n",
    "What we're actually interested in is the percent growth of any given stock.\n",
    "Thus I propose we divide by the furthest-back data point to normalize everything to be multiples of the starting time point.\n",
    "Thus we have percent growth independent of stock price and zero is true zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily use the oldest open price to normalize all price metrics\n",
    "open_norm = dat_open / dat_open[0]\n",
    "close_norm = dat_close / dat_open[0]\n",
    "high_norm = dat_high / dat_open[0]\n",
    "low_norm = dat_low / dat_open[0]\n",
    "volume_norm = dat_volume / dat_volume[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, squeeze=True)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "ax1.plot(open_norm, label='open')\n",
    "ax1.plot(close_norm, label='close')\n",
    "ax1.plot(high_norm, label='high')\n",
    "ax1.plot(low_norm, label='low')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(volume_norm, label='volume')\n",
    "ax2.legend()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it might actually be the case that the difference between adjacent time points is more important than the general trend.\n",
    "Thus we could examine day-to-day relative changes like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_diff = np.array([(dat_open[i]-dat_open[i-1])/dat_open[i-1] for i in range(1, len(dat_open))])\n",
    "close_diff = np.array([(dat_close[i]-dat_close[i-1])/dat_close[i-1] for i in range(1, len(dat_close))])\n",
    "high_diff = np.array([(dat_high[i]-dat_high[i-1])/dat_high[i-1] for i in range(1, len(dat_high))])\n",
    "low_diff = np.array([(dat_low[i]-dat_low[i-1])/dat_low[i-1] for i in range(1, len(dat_low))])\n",
    "volume_diff = np.array([(dat_volume[i]-dat_volume[i-1])/dat_volume[i-1] for i in range(1, len(dat_volume))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, squeeze=True)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "ax1.plot(open_diff, label='open')\n",
    "ax1.plot(close_diff, label='close')\n",
    "ax1.plot(high_diff, label='high')\n",
    "ax1.plot(low_diff, label='low')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(volume_diff, label='volume')\n",
    "ax2.legend()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the price difference graph, we see that the values are quite small.\n",
    "It may be the case that we need to scale up all such price difference normalizations to put them into a more appropriate range for whatever ANN design we choose to use.\n",
    "\n",
    "From all the graphs show, it's likely that the use of open, close, high, *and* low is unnecessary.\n",
    "We could likely come up with one or two values to summarize this.\n",
    "Obvious solutions include the high-low average or the open-close average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
